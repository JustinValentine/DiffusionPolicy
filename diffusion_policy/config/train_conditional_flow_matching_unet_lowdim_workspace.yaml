defaults:
  - task: square_lowdim_abs
  - ema: power
  - monitoring
  - data_loader/lowdim@_global_
  - training: training
  - optimizer: adam
  - policy: conditional_flow_matching_policy
  - override policy/inner_model: unet
  - override policy/obs_encoder: flatten_time
  - _self_

name: train_conditional_flow_matching_unet_lowdim
_target_: diffusion_policy.workspace.train_workspace.TrainWorkspace

shape_meta: ${task.shape_meta}

policy:
  inner_model:
    down_dims: [256, 512, 1024]
  target_sigma_min: 0.1
  map_from_last_obs: True
  obs_to_action:
    _target_: diffusion_policy.dataset.robomimic_replay_dataset.RobomimicObsToAction
    abs_action: ${task.abs_action}

task_name: ${task.name}
exp_name: "default"

horizon: 16
n_obs_steps: 2
n_action_steps: 8
n_latency_steps: 0
past_action_visible: False
keypoint_visible_rate: 1.0
num_inference_steps: 100


